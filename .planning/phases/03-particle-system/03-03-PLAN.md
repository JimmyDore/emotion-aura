---
phase: 03-particle-system
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - src/particles/FaceLandmarkTracker.ts
  - src/particles/QualityScaler.ts
  - src/main.ts
  - src/style.css
autonomous: false

must_haves:
  truths:
    - "Particles spawn from the user's face position and flow outward"
    - "Emotion changes cause particles to morph color and behavior in-place (no kill/respawn)"
    - "Stronger expressions produce more particles and brighter glow (intensity scaling)"
    - "When FPS drops below 30, particle count reduces automatically"
    - "Webcam feed is dimmed behind bright glowing particles"
    - "A subtle quality indicator shows when quality has been reduced"
  artifacts:
    - path: "src/particles/FaceLandmarkTracker.ts"
      provides: "Converts MediaPipe face landmarks to scene coordinates for particle spawning"
      exports: ["FaceLandmarkTracker"]
    - path: "src/particles/QualityScaler.ts"
      provides: "FPS monitoring and adaptive particle count scaling"
      exports: ["QualityScaler"]
    - path: "src/main.ts"
      provides: "Full particle pipeline wired into render loop"
      contains: "ParticleSystem"
    - path: "src/style.css"
      provides: "Dimmed webcam feed and quality indicator styles"
      contains: "brightness"
  key_links:
    - from: "src/main.ts"
      to: "src/particles/ParticleSystem.ts"
      via: "Creates ParticleSystem in live experience setup, calls update() in animate loop"
      pattern: "particleSystem\\.update"
    - from: "src/main.ts"
      to: "src/particles/FaceLandmarkTracker.ts"
      via: "Feeds face landmarks from FaceDetector result to FaceLandmarkTracker"
      pattern: "faceLandmarkTracker"
    - from: "src/main.ts"
      to: "src/particles/EmotionProfile.ts"
      via: "Uses blendProfiles with EmotionState scores to get current particle config"
      pattern: "blendProfiles"
    - from: "src/particles/QualityScaler.ts"
      to: "src/particles/ParticlePool.ts"
      via: "Calls pool.setMaxActive() to reduce particle count when FPS is low"
      pattern: "setMaxActive"
    - from: "src/particles/FaceLandmarkTracker.ts"
      to: "SceneManager camera"
      via: "Uses camera aspect ratio for landmark-to-scene coordinate conversion"
      pattern: "aspect"
---

<objective>
Wire everything together: face-anchored particle spawning from MediaPipe landmarks, emotion-driven profile blending in the render loop, adaptive quality scaling, and the dimmed webcam aesthetic. This plan completes the particle system phase.

Purpose: Plans 01 and 02 built the rendering engine and emotion configs independently. This plan connects them to the live detection pipeline so particles actually respond to the user's face and emotions in real-time.
Output: Full working particle experience -- ethereal glowing particles emanate from the user's face, morph based on detected emotion, scale with expression intensity, and degrade gracefully under load.
</objective>

<execution_context>
@/Users/jimmydore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jimmydore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-particle-system/03-CONTEXT.md
@.planning/phases/03-particle-system/03-RESEARCH.md
@.planning/phases/03-particle-system/03-01-SUMMARY.md
@.planning/phases/03-particle-system/03-02-SUMMARY.md
@src/main.ts
@src/scene/SceneManager.ts
@src/state/EmotionState.ts
@src/ml/FaceDetector.ts
@src/core/types.ts
@src/core/constants.ts
@src/style.css
@src/particles/ParticleSystem.ts
@src/particles/ParticlePool.ts
@src/particles/EmotionProfile.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: FaceLandmarkTracker and QualityScaler</name>
  <files>
    src/particles/FaceLandmarkTracker.ts
    src/particles/QualityScaler.ts
  </files>
  <action>
1. Create `src/particles/FaceLandmarkTracker.ts`:
   - Purpose: Extract face center from MediaPipe FaceLandmarker results and convert to Three.js scene coordinates
   - `update(faceLandmarks: NormalizedLandmark[] | undefined, aspect: number): { x: number, y: number } | null`
     - If no landmarks or empty, return null
     - Use nose tip landmark (index 1) as face center -- it's the most stable point
     - Convert MediaPipe normalized coordinates [0,1] to orthographic scene coords:
       ```ts
       // MediaPipe: x=0 left, x=1 right, y=0 top, y=1 bottom
       // Webcam is mirrored (scaleX(-1)), so scene x must also mirror
       const sceneX = -(landmark.x * 2 - 1) * aspect;  // negate for mirror
       const sceneY = -(landmark.y * 2 - 1);            // flip y (MediaPipe y=0 is top)
       ```
     - Apply simple EMA smoothing to the output position (alpha ~0.3) to prevent jitter. Store previous position internally.
   - `reset()`: Clear stored position (call on face lost)
   - Import `NormalizedLandmark` type from `@mediapipe/tasks-vision` (it's the landmark type from FaceLandmarker results)

2. Create `src/particles/QualityScaler.ts`:
   - Constructor takes `pool: ParticlePool` reference (from ParticleSystem.getPool())
   - Import `QUALITY_FPS_THRESHOLD`, `QUALITY_SCALE_DELAY`, `QUALITY_MIN_PARTICLES`, `MAX_PARTICLES` from constants
   - Track FPS using a simple rolling average (last 30 frames)
   - `update(dt: number)`: Add frame time to rolling buffer. Compute average FPS. If average FPS < QUALITY_FPS_THRESHOLD for QUALITY_SCALE_DELAY seconds continuously, reduce max active particles by 20% (multiply current max by 0.8, floor at QUALITY_MIN_PARTICLES). Call `pool.setMaxActive(newMax)`. If FPS recovers above threshold + 5 (hysteresis) for QUALITY_SCALE_DELAY seconds, increase max active by 10% (cap at MAX_PARTICLES).
   - `isScaled(): boolean` -- returns true if current max is below MAX_PARTICLES (for UI indicator)
   - `getCurrentMax(): number` -- for debug/display
   - Create and manage a small DOM indicator element:
     - When quality is reduced: show a small icon/text in bottom-left corner (e.g., small lightning bolt emoji or text "Quality: reduced") with class `quality-indicator`
     - When quality recovers to full: hide the indicator
     - `dispose()`: Remove DOM element
  </action>
  <verify>
    Run `npx tsc --noEmit` -- should compile cleanly.
    FaceLandmarkTracker should correctly mirror x-coordinate (verify the negation logic matches webcam mirror transform).
  </verify>
  <done>
    FaceLandmarkTracker converts MediaPipe landmarks to scene coordinates with EMA smoothing. QualityScaler monitors FPS and adaptively reduces/increases particle count with hysteresis and a visible quality indicator.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire particle system into main.ts render loop and style webcam dimming</name>
  <files>
    src/main.ts
    src/style.css
  </files>
  <action>
1. Update `src/style.css`:
   - Change `#webcam` rule to add dimming: `filter: brightness(0.3);` (dark-tinted mirror aesthetic)
   - Add quality indicator styles:
     ```css
     .quality-indicator {
       position: fixed;
       bottom: 16px;
       left: 16px;
       z-index: 50;
       background: rgba(0, 0, 0, 0.5);
       backdrop-filter: blur(8px);
       border-radius: 6px;
       padding: 6px 10px;
       font-size: 11px;
       color: rgba(255, 255, 255, 0.5);
       pointer-events: none;
       transition: opacity 0.5s ease;
     }
     ```

2. Update `src/main.ts` -- add particle system to the live experience section:

   **New imports** (add at top):
   ```ts
   import { ParticleSystem } from './particles/ParticleSystem.ts';
   import { FaceLandmarkTracker } from './particles/FaceLandmarkTracker.ts';
   import { QualityScaler } from './particles/QualityScaler.ts';
   import { blendProfiles } from './particles/EmotionProfile.ts';
   import { SPAWN_RATE_BASE, SPAWN_RATE_MAX, PARTICLE_SIZE_BASE, PARTICLE_LIFETIME_BASE } from './core/constants.ts';
   ```

   **New module-level variables** (alongside existing ones):
   ```ts
   let particleSystem: ParticleSystem | null = null;
   let qualityScaler: QualityScaler | null = null;
   ```

   **In the live experience section** (after sceneManager init, before animate):
   ```ts
   // Particle system
   particleSystem = new ParticleSystem(sceneManager.scene);
   const faceLandmarkTracker = new FaceLandmarkTracker();
   qualityScaler = new QualityScaler(particleSystem.getPool());
   ```

   **In the animate() function** -- add particle spawning and updating AFTER emotion state update, BEFORE sceneManager.render():

   ```ts
   // Track time for particle system
   const now = performance.now() / 1000;
   const dt = Math.min(now - lastTime, 0.05); // Cap dt to prevent spiral on lag
   lastTime = now;
   ```
   (Add `let lastTime = performance.now() / 1000;` before animate definition)

   **Particle spawning logic** (inside animate, after emotionOverlay update):
   ```ts
   // Get current emotion state for particle profile
   const currentEmotion = emotionState.getCurrent();
   const profile = blendProfiles(currentEmotion.scores);

   // Get face position in scene coordinates
   const aspect = window.innerWidth / window.innerHeight;
   // Access face landmarks from faceDetector result (the raw result variable)
   const faceLandmarks = result?.faceLandmarks?.[0];
   const facePos = faceLandmarkTracker.update(faceLandmarks, aspect);

   if (facePos && currentEmotion.faceDetected) {
     particleSystem.setSpawnCenter(facePos.x, facePos.y);

     // Spawn particles based on emotion profile and intensity
     const intensity = currentEmotion.intensity;
     const spawnRate = SPAWN_RATE_BASE * profile.spawnRateMultiplier * (0.3 + 0.7 * intensity);
     const particlesToSpawn = spawnRate * dt;

     // Fractional spawning: accumulate and spawn whole particles
     spawnAccumulator += particlesToSpawn;
     while (spawnAccumulator >= 1) {
       spawnAccumulator -= 1;

       // Random angle within spread
       const baseAngle = Math.atan2(profile.direction[1], profile.direction[0]);
       const angle = baseAngle + (Math.random() - 0.5) * profile.spread;
       const speed = profile.speed * (0.5 + Math.random() * 0.5) * (0.5 + intensity * 0.5);
       const vx = Math.cos(angle) * speed;
       const vy = Math.sin(angle) * speed;

       // Pick random color from profile palette
       const colorIdx = Math.floor(Math.random() * profile.colors.length);
       const [r, g, b] = profile.colors[colorIdx];

       // Scale size and lifetime by intensity
       const size = PARTICLE_SIZE_BASE * profile.sizeMultiplier * (0.5 + Math.random() * 0.5) * (0.7 + intensity * 0.3);
       const lifetime = PARTICLE_LIFETIME_BASE * profile.lifetimeMultiplier * (0.8 + Math.random() * 0.4);

       // Spawn at face position with slight random offset
       const offsetX = (Math.random() - 0.5) * 0.15;
       const offsetY = (Math.random() - 0.5) * 0.15;

       particleSystem.spawn(
         facePos.x + offsetX, facePos.y + offsetY,
         vx, vy,
         r, g, b,
         size, lifetime
       );
     }
   } else {
     faceLandmarkTracker.reset();
   }

   // Update particle system (physics + GPU buffer sync)
   particleSystem.update(dt, now);

   // Quality scaling
   qualityScaler.update(dt);
   ```
   (Add `let spawnAccumulator = 0;` before animate definition)

   **IMPORTANT**: The `result` variable from faceDetector.detect() is currently scoped inside the `if (result !== null)` block. The face landmarks need to be accessible for FaceLandmarkTracker. Restructure slightly: store the last non-null result's landmarks in a variable accessible to particle spawning. Specifically:
   - Before the animate function, declare `let lastFaceLandmarks: any = undefined;`
   - Inside the `if (result !== null)` block where blendshapes are processed, also save: `lastFaceLandmarks = result.faceLandmarks?.[0];`
   - In the else branch (no blendshapes): `lastFaceLandmarks = undefined;`
   - When face is lost (decayToNeutral path): `lastFaceLandmarks = undefined;`
   - Use `lastFaceLandmarks` for FaceLandmarkTracker.update() instead of `result?.faceLandmarks`

   **HMR cleanup** -- add to the dispose block:
   ```ts
   if (particleSystem) {
     particleSystem.dispose();
     particleSystem = null;
   }
   if (qualityScaler) {
     qualityScaler.dispose();
     qualityScaler = null;
   }
   ```
  </action>
  <verify>
    Run `npx tsc --noEmit` -- should compile cleanly.
    Run `npx vite build` -- should build successfully.
    Run `npm run dev` and open in browser:
    1. Webcam should appear dimmed (brightness 0.3)
    2. When face is detected, glowing particles should emanate from face position
    3. Smile (happy) should produce warm gold/pink upward-flowing particles
    4. Look sad should produce blue downward rain-like particles
    5. Angry expression should produce red/orange chaotic flame-like particles
    6. Surprised face should produce bright burst effect
    7. Neutral should produce subtle silver ambient drift
    8. Emotion transitions should morph smoothly (particles change color/behavior, not respawn)
    9. Moving head should cause spawn point to follow smoothly
  </verify>
  <done>
    Full particle pipeline wired: face landmarks drive spawn position, emotion scores drive visual profile, intensity scales particle density and brightness. Webcam dimmed for dark aesthetic. Quality scaling active with visible indicator.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete emotion-reactive particle system: ethereal glowing particles spawn from face position, morph based on detected emotion (5 distinct visual profiles), scale with expression intensity, webcam dimmed for dramatic dark aesthetic, adaptive quality scaling with indicator</what-built>
  <how-to-verify>
    1. Open the app (npm run dev) and grant camera access
    2. Verify the webcam feed is dimmed (dark-tinted mirror look)
    3. Verify glowing particles spawn from around your face (not random screen positions)
    4. Move your head -- particles should follow smoothly
    5. Smile (happy) -- expect warm gold/pink particles flowing upward, playful motion
    6. Look sad -- expect blue particles drifting down slowly, rain-like
    7. Angry expression -- expect red/orange chaotic fast particles, flame-like
    8. Surprised face -- expect cyan/yellow burst outward
    9. Return to neutral -- expect subtle silver ambient drift
    10. Verify transitions between emotions are smooth morphs (particles change color/speed, not disappear and respawn)
    11. Verify stronger expressions produce more dramatic effects (more particles, brighter glow)
    12. Check the FPS counter (top-left) stays above 30. If it dips, a quality indicator should appear (bottom-left)
  </how-to-verify>
  <resume-signal>Type "approved" or describe any visual/behavioral issues to fix</resume-signal>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes
- `npx vite build` succeeds
- Particles spawn from face position and flow outward
- All 5 emotions produce visually distinct particle behaviors
- Webcam is dimmed (brightness 0.3)
- Emotion transitions morph in-place
- Quality scaling reduces particle count when FPS < 30
- No memory leaks on HMR (dispose cleans up particle system)
</verification>

<success_criteria>
- PRT-01: Organic/fluid particles with custom GLSL shaders (soft glow, additive blending)
- PRT-02: Happy = warm gold/pink, lively upward particles
- PRT-03: Sad = blue, slow downward rain-like particles
- PRT-04: Angry = red/orange, fast chaotic flame-like particles
- PRT-05: Surprised = cyan/yellow burst/explosion
- PRT-06: Neutral = grey/silver calm ambient drift
- PRT-07: Particles spawn from face position (tracked via landmarks)
- PRT-08: Auto-quality scaling when FPS < 30
</success_criteria>

<output>
After completion, create `.planning/phases/03-particle-system/03-03-SUMMARY.md`
</output>
