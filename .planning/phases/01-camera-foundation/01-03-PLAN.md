---
phase: 01-camera-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-01", "01-02"]
files_modified:
  - src/ui/MobileGate.ts
  - src/main.ts
autonomous: false

must_haves:
  truths:
    - "User on mobile sees a 'best on desktop' message with option to continue anyway"
    - "User sees a pre-prompt explanation before the browser permission dialog appears"
    - "After granting permission, user sees a progress bar while ML models download"
    - "After loading completes, user sees their mirrored webcam feed filling the viewport"
    - "If camera is denied or fails, user sees a specific error with recovery guidance"
    - "Camera and model loading happen in parallel for faster startup"
  artifacts:
    - path: "src/ui/MobileGate.ts"
      provides: "Mobile device detection and 'best on desktop' screen"
      exports: ["MobileGate"]
    - path: "src/main.ts"
      provides: "Complete app orchestration: mobile check -> permission -> parallel load -> live experience"
      contains: "Promise.all"
  key_links:
    - from: "src/main.ts"
      to: "src/ui/MobileGate.ts"
      via: "First check on startup"
      pattern: "isMobile|MobileGate"
    - from: "src/main.ts"
      to: "src/ui/PermissionScreen.ts"
      via: "Shows permission screen, waits for user click"
      pattern: "PermissionScreen"
    - from: "src/main.ts"
      to: "src/camera/CameraManager.ts"
      via: "requestAccess() called after user clicks Start"
      pattern: "requestAccess"
    - from: "src/main.ts"
      to: "src/ml/ModelLoader.ts"
      via: "loadAll() called in parallel with camera access"
      pattern: "loadAll|Promise\\.all"
    - from: "src/main.ts"
      to: "src/ui/LoadingScreen.ts"
      via: "updateProgress() during model download"
      pattern: "updateProgress"
    - from: "src/main.ts"
      to: "src/ui/ErrorScreen.ts"
      via: "show(error) on camera failure"
      pattern: "ErrorScreen.*show|show.*CameraError"
    - from: "src/main.ts"
      to: "src/scene/SceneManager.ts"
      via: "render loop starts after initialization complete"
      pattern: "SceneManager"
    - from: "src/main.ts"
      to: "#webcam"
      via: "Video element made visible and receives camera stream"
      pattern: "webcam.*display|style\\.display"
---

<objective>
Wire all Phase 1 components into the complete three-screen startup flow (Permission -> Loading -> Live Experience), add mobile device detection gate, and verify the full user experience works end-to-end.

Purpose: This is the integration plan that transforms isolated modules into the working product. Without this, the components exist but the user sees nothing. This plan produces the complete Phase 1 deliverable.
Output: A fully working app where the user can grant camera access, see loading progress, and see their mirrored webcam feed with a transparent Three.js overlay -- the foundation for the entire Emotion Aura experience.
</objective>

<execution_context>
@/Users/jimmydore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jimmydore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-camera-foundation/01-RESEARCH.md
@.planning/phases/01-camera-foundation/01-01-SUMMARY.md
@.planning/phases/01-camera-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: MobileGate module and main.ts full orchestration</name>
  <files>
    src/ui/MobileGate.ts
    src/main.ts
  </files>
  <action>
    1. Create src/ui/MobileGate.ts as a class:
       - Static method: isMobile(): boolean
         - Method 1: Check navigator.userAgentData.mobile if available (Client Hints API -- Chrome/Edge)
         - Method 2: Check window.matchMedia('(max-width: 768px)').matches
         - Method 3: Check navigator.maxTouchPoints > 0 AND window.matchMedia('(pointer: coarse)').matches
         - Return true if any method detects mobile
       - Constructor takes container element (div#app)
       - Creates a div.screen.mobile-gate-screen with:
         - A desktop icon (SVG or emoji)
         - Heading: "Best on Desktop"
         - Message: "This experience uses your webcam and works best on a desktop computer with a larger screen."
         - A "Continue Anyway" link/button (smaller, text-style, for tablets) with class .btn-text
       - Method: show(): Promise&lt;void&gt; -- returns a promise that resolves when user clicks "Continue Anyway"
       - Method: hide(): void
       - Export class

    2. Rewrite src/main.ts to orchestrate the complete startup flow:

       Import all modules:
       - SceneManager from scene/SceneManager
       - CameraManager from camera/CameraManager
       - ModelLoader from ml/ModelLoader
       - PermissionScreen from ui/PermissionScreen
       - LoadingScreen from ui/LoadingScreen
       - ErrorScreen from ui/ErrorScreen
       - MobileGate from ui/MobileGate
       - Stats from 'stats.js'
       - CameraError type from core/types

       On DOMContentLoaded, run the startup flow:

       a. MOBILE CHECK:
          - If MobileGate.isMobile() returns true:
            - Create MobileGate, call show() (returns promise)
            - Await the promise (user clicked "Continue Anyway")
            - Hide MobileGate, continue to next step

       b. PERMISSION SCREEN:
          - Create PermissionScreen, call show()
          - Wait for user to click "Start Experience" via onStart callback (wrap in a Promise)
          - Hide PermissionScreen

       c. LOADING + CAMERA (parallel):
          - Create LoadingScreen, call show()
          - Create CameraManager and ModelLoader instances
          - Run in parallel with Promise.all:
            - cameraManager.requestAccess()
            - modelLoader.loadAll((progress) => loadingScreen.updateProgress(progress))
          - If camera fails: catch error, hide LoadingScreen, create ErrorScreen, show(error as CameraError)
            - If ErrorScreen has retry: wire onRetry to restart from step (c)
          - If models fail: show error screen with generic model download error
          - On success: hide LoadingScreen

       d. LIVE EXPERIENCE:
          - Get video#webcam element, call cameraManager.attachToVideo(video)
          - Wait for video loadedmetadata
          - Make video visible (display: block)
          - Create SceneManager with canvas#scene
          - Create Stats, append to body
          - Start render loop:
            ```
            function animate() {
              stats.begin();
              sceneManager.render();
              stats.end();
              rafId = requestAnimationFrame(animate);
            }
            animate();
            ```

       e. HMR CLEANUP:
          - import.meta.hot.dispose: cancel rAF, dispose SceneManager, stop CameraManager, remove Stats DOM

       IMPORTANT: The flow must be sequential (mobile check -> permission -> loading -> live) but the loading step runs camera + models in parallel. Each screen transition should feel smooth -- hide the previous screen before showing the next.
  </action>
  <verify>
    Run `npx tsc --noEmit` -- no TypeScript errors.
    Run `npm run dev` and test the full flow:
    1. Page loads with dark background
    2. Permission screen appears with explanation and Start button
    3. Click Start -> loading screen appears with progress bar
    4. Progress bar fills as models download
    5. After loading, webcam feed appears mirrored
    6. Stats.js FPS counter visible
    7. No console errors
  </verify>
  <done>
    Complete three-screen flow works: Permission -> Loading (with progress) -> Live mirrored webcam feed. Mobile detection gate shows on narrow viewports. Camera errors show specific messages. All components are wired together through main.ts orchestration.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify complete Phase 1 experience</name>
  <what-built>
    The complete Camera and Foundation phase: Vite + TypeScript + Three.js project scaffold, three-screen startup flow (Permission -> Loading -> Live), full camera error handling, ML model download with progress tracking, mobile detection gate, and mirrored webcam display with transparent Three.js overlay.
  </what-built>
  <how-to-verify>
    1. Open the dev server URL (likely http://localhost:5173) in Chrome
    2. You should see a dark-themed permission screen with:
       - "Emotion Aura" heading
       - Explanation of why camera is needed
       - Privacy note about local processing
       - "Start Experience" button
    3. Click "Start Experience"
    4. Grant camera permission when the browser asks
    5. You should see a loading screen with:
       - "Loading AI Models..." heading
       - A progress bar that fills from 0% to 100%
       - Status text updating as models download
    6. After loading completes, you should see:
       - Your mirrored webcam feed filling the viewport
       - Stats.js FPS counter in the top-left corner
       - Dark background with no white edges
    7. Wave your hand -- confirm the feed is mirrored (your right hand should appear on the left side of the screen)
    8. (Optional) Test error handling: open DevTools, disable camera in site settings, refresh -- you should see an error screen with recovery instructions
    9. (Optional) Resize browser window very narrow (under 768px width) and refresh -- you should see the "Best on Desktop" message with a "Continue Anyway" option
  </how-to-verify>
  <resume-signal>Type "approved" if the experience works as described, or describe any issues you see.</resume-signal>
</task>

</tasks>

<verification>
Phase 1 is complete when ALL of these are true:
1. Permission screen appears before browser permission dialog
2. Loading screen shows real progress bar (not spinner) during model downloads
3. Mirrored webcam feed displays after loading completes
4. Three.js transparent canvas overlay is positioned over the video
5. Stats.js FPS counter is visible
6. Camera denial shows "denied" error with address bar recovery hint
7. No camera shows "not found" error
8. Camera in use shows "in use" error with app closure hint
9. Mobile viewport shows "best on desktop" message with "Continue Anyway" option
10. No console errors during normal flow
11. TypeScript compiles with no errors (`npx tsc --noEmit`)
12. HMR works without leaking WebGL contexts or camera streams
</verification>

<success_criteria>
- User sees explanation before browser permission prompt (CAM-02)
- User sees mirrored webcam feed after granting permission (CAM-01)
- User sees specific error messages for denied/unavailable/in-use camera (CAM-03)
- User sees loading progress bar while models download (CAM-04)
- Mobile user sees "best on desktop" message (CAM-05)
- All 5 requirements covered: CAM-01 through CAM-05
</success_criteria>

<output>
After completion, create `.planning/phases/01-camera-foundation/01-03-SUMMARY.md`
</output>
